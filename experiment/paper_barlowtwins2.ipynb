{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4533ee81-d579-4867-b15b-aa7f3f8f385f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment Introduction\n",
    "\n",
    "Background, \n",
    "In order to do ablation experiment, we have diffculty like\n",
    "1. most of them are same, we have to repeat many times.\n",
    "2. too many model, config, code hard to manage and save. too messy\n",
    "\n",
    "\n",
    "For all kind of SSL training workflow, we have to define the hyperparameters includes 4 aspect,\n",
    "Dataset\n",
    "Model\n",
    "Training\n",
    "Saving COnfig\n",
    "\n",
    "\n",
    "\n",
    "How to Use this Experiment?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5e60f-6c7d-47b6-8b30-5ad2e6c94b09",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64951e3b-e012-4ed5-8846-03eed103c696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71222088-d62f-40fc-b935-f9c8ee99a579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import config\n",
    "import sys \n",
    "sys.path.append(\"C:/Users/isxzl/OneDrive/Code/AutoSSL\")\n",
    "import yaml\n",
    "from torchvision.transforms import RandomRotation,GaussianBlur,ColorJitter\n",
    "from autoSSL.evaluate import eval_KNN,eval_linear,eval_KNNplot,pipe_collate\n",
    "from autoSSL.models import BarlowTwins, BYOL, MoCo, SimCLR, SimSiam, VICReg ,Toymodel, pipe_model \n",
    "from autoSSL.utils import embedding_feature,ck_callback,dict2transformer,join_dir,ContinuousCSVLogger  \n",
    "from autoSSL.data import PipeDataset\n",
    "from autoSSL.train import Trainer\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eba85e-c2d4-4ed3-a276-2b03ff82f764",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Global Baseline Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16334f28-7fca-42b0-afbc-f19c2b4ee76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0e5479-43a3-4b63-b9e2-b8ce70103290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML file\n",
    "with open('global.yaml', 'r') as file:\n",
    "    global_config = yaml.safe_load(file)\n",
    "\n",
    "# Write your experiment notebook name here\n",
    "global_config[\"experiment\"]=\"paper_barlowtwins\"   \n",
    "\n",
    "global_config[\"prjhead_dim\"]=[2048,2048]    \n",
    "global_config[\"predhead_dim\"]=[]\n",
    "global_config[\"loss_func\"]=\"BarlowTwinsLoss\"     \n",
    "global_config[\"view_model\"]=\"None\"     \n",
    "global_config[\"view\"]=2 \n",
    "global_config[\"stop_gradient\"]=False   \n",
    "global_config[\"optimizer\"]=\"LARS\"    \n",
    "global_config[\"schedule\"]=\"LambdaLR\"   \n",
    "global_config[\"model\"]=\"Toymodel\"\n",
    "global_config[\"batch_size\"]=128\n",
    "global_config[\"input_size\"]=32\n",
    "\n",
    "# Define global view function\n",
    "global_SSL_augmentation = {\n",
    "    'RandomResizedCrop': {'size': global_config[\"input_size\"], \"scale\":(0.08,1.0)},\n",
    "    'RandomApply':{'transforms':[RandomRotation(degrees=90)], 'p':0},\n",
    "    'RandomHorizontalFlip': {'p': 0.5},\n",
    "    'RandomVerticalFlip':  {'p':0},\n",
    "    'RandomApply':{'transforms': [ColorJitter(brightness=0.4,contrast=0.4,saturation=0.4,hue=0.1)], 'p':0.8},\n",
    "    'RandomGrayscale' :{'p':0.2},\n",
    "    #'RandomSolarize':{'threshold':128, 'p':0.1},\n",
    "    'RandomApply':{'transforms':[GaussianBlur(kernel_size=3,sigma=(0.1, 2))],'p':0},\n",
    "    'ToTensor': {},\n",
    "    'Normalize': {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "}\n",
    "\n",
    "test_SSL_augmentation = {\n",
    "    'ToTensor': {},\n",
    "    'Normalize': {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "} \n",
    "\n",
    "# THIS IS THE CODE TO Monitor the KNN accuracy for each epoch\n",
    "p_knndata= PipeDataset(input_dir=global_config[\"path_to_test_cifar10\"], \n",
    "        augmentation=dict2transformer(test_SSL_augmentation,view=1), \n",
    "        batch_size=global_config[\"batch_size\"],num_workers=global_config[\"num_workers\"]).dataloader\n",
    "p_knndata=[p_knndata,10]  # The second number is the classes number of this datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdbd76-a430-4e54-903f-d9ca1d69e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_model(config=global_config,MonitoringbyKNN=p_knndata) # All save the validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a869f3e-3e94-4d05-bec5-6fdd31695b58",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Grid Run Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6193d5-6e9b-449e-8f33-c0f4dd0e07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e6970-4604-485e-bd37-60383de96b81",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config1: Baseline of Cifar with Batch 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1352c0-9e27-470a-919d-af85ba9365b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\AutoGPT\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:615: UserWarning: Checkpoint directory C:\\Users\\isxzl\\OneDrive\\Code\\AutoSSL\\experiment\\experiment_checkpoints\\paper_barlowtwins\\BT_Baseline_NNNNN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                      | Params\n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | Sequential                | 11.2 M\n",
      "1 | criterion       | BarlowTwinsLoss           | 0     \n",
      "2 | projection_head | BarlowTwinsProjectionHead | 9.4 M \n",
      "--------------------------------------------------------------\n",
      "20.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 M    Total params\n",
      "82.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  11%|███████▎                                                        | 11/97 [00:08<01:03,  1.35it/s, v_num=0]"
     ]
    }
   ],
   "source": [
    "\n",
    "for baseline in [1]:\n",
    "    # MAKE YOUR OWN CONFIG\n",
    "    config=global_config.copy()\n",
    "    # Fill the config\n",
    "    SSL_augmentation=global_SSL_augmentation.copy()\n",
    "    config[\"name\"]=f\"BT_Baseline_NNNNN\"\n",
    "    config[\"batch_size\"]=512\n",
    "    config[\"max_epochs\"]=200\n",
    "    \n",
    "\n",
    "    # THIS IS THE CODE TO LOAD DATASET\n",
    "    pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "    \n",
    "    # THIS IS THE CODE TO LOAD MODEL\n",
    "    #pmodel=pipe_model(config=config) \n",
    "    pmodel=pipe_model(config=config,MonitoringbyKNN=p_knndata) # All save the validation\n",
    "    \n",
    " \n",
    "    # Use this if you want to START a train\n",
    "    trainer=Trainer(config, model_mode=\"start\",check_val_every_n_epoch =5) #precision='16-mixed',\n",
    "    trainer.fit(pmodel, pdata.dataloader,)  \n",
    "    \n",
    "    # Use this if you want to CONTINUE a train\n",
    "    #trainer=Trainer(config, model_mode=\"continue\", extra_epoch=1,precision='16-mixed')\n",
    "    #trainer.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  \n",
    "    \n",
    "    del pdata\n",
    "    del pmodel\n",
    "    del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a70d5bb-279d-47b1-8850-dd2288e5e568",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Config2: Different batch vs FastSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d075e9b-a5f2-4979-9d34-aa8ffcb108d2",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb66c1a-89fa-4ce2-9f35-92ba04726170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch_num in [16,32,64,128,256,512,1024,2048,4096]:\n",
    "#for batch_num in [256]:\n",
    "    # MAKE YOUR OWN CONFIG\n",
    "    config=global_config.copy()\n",
    "    # Fill the config\n",
    "    SSL_augmentation=global_SSL_augmentation.copy()\n",
    "    config[\"name\"]=f\"Toymodel_all_batch_{batch_num}\"\n",
    "    config[\"views\"]=3\n",
    "    config[\"views_mode\"]=\"all\"  # overZ #overLoss #overBoth\n",
    "    config[\"model\"]=\"Toymodel\"\n",
    "    config[\"predhead\"]=True\n",
    "    config[\"batch_size\"]=batch_num\n",
    "    config[\"max_epochs\"]=5\n",
    "    # THIS IS THE CODE TO LOAD DATASET\n",
    "    pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "    \n",
    "    # THIS IS THE CODE TO LOAD MODEL\n",
    "    pmodel=pipe_model(config=config) \n",
    "    #pmodel=pipe_model(config=config,MonitoringbyKNN=p_knndata) # All save the validation\n",
    "    \n",
    " \n",
    "    # Use this if you want to START a train\n",
    "    trainer=Trainer(config, model_mode=\"start\",precision='16-mixed') #,check_val_every_n_epoch =5\n",
    "    trainer.fit(pmodel, pdata.dataloader)  \n",
    "    \n",
    "    # Use this if you want to CONTINUE a train\n",
    "    #trainer=Trainer(config, model_mode=\"continue\", extra_epoch=1,precision='16-mixed')\n",
    "    #trainer.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  \n",
    "    \n",
    "    del pdata\n",
    "    del pmodel\n",
    "    del trainer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d877c7-b5f9-4dd9-ae01-04f29327fe52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VICREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67682be1-2079-464a-97e5-26c474f5bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for batch_num in [32, 64,128,256,512,1024,2048]:\n",
    "    # MAKE YOUR OWN CONFIG\n",
    "    config=global_config.copy()\n",
    "    # Fill the config\n",
    "    SSL_augmentation=global_SSL_augmentation.copy()\n",
    "    config[\"name\"]=f\"barlow_batch_{batch_num}\"\n",
    "    config[\"batch\"]=batch_num\n",
    "    config[\"model\"]=\"BarlowTwins\"\n",
    "\n",
    "    # THIS IS THE CODE TO LOAD DATASET\n",
    "    pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "    # THIS IS THE CODE TO LOAD MODEL\n",
    "    pmodel=pipe_model(config=config)\n",
    "\n",
    "    # Use this if you want to START a train\n",
    "    trainer=Trainer(config, model_mode=\"start\")\n",
    "    trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "    del pdata\n",
    "    del pmodel\n",
    "    del trainer\n",
    "    # Use this if you want to CONTINUE to train\n",
    "    #trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "    #trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c6a03-29f7-449a-af3a-05075be370e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Config more ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e13b52-9b87-4072-9103-b8fd93f3de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for batch_num in [32, 64,128,256,512,1024,2048]:\n",
    "    # MAKE YOUR OWN CONFIG\n",
    "    config=global_config.copy()\n",
    "    # Fill the config\n",
    "    SSL_augmentation=global_SSL_augmentation.copy()\n",
    "    config[\"name\"]=f\"barlow_batch_{batch_num}\"\n",
    "    config[\"batch\"]=batch_num\n",
    "    config[\"model\"]=\"BarlowTwins\"\n",
    "\n",
    "    # THIS IS THE CODE TO LOAD DATASET\n",
    "    pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "    # THIS IS THE CODE TO LOAD MODEL\n",
    "    pmodel=pipe_model(config=config)\n",
    "\n",
    "    # Use this if you want to START a train\n",
    "    trainer=Trainer(config, model_mode=\"start\")\n",
    "    trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "    del pdata\n",
    "    del pmodel\n",
    "    del trainer\n",
    "    # Use this if you want to CONTINUE to train\n",
    "    #trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "    #trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50686839-6777-4c26-b7f6-02b871ac184a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad6455-b8c3-4d5d-b6eb-5627bd52fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_augmentation = {\n",
    "    'RandomResizedCrop': {'size': (global_config[\"input_size\"], global_config[\"input_size\"])},\n",
    "    'ToTensor': {},\n",
    "    'Normalize': {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "}\n",
    "collate =pipe_collate(address=\"experiment_checkpoints/views VS model/\", reg=\"Toymodel_all_batch_[0-9]+\")\n",
    "\n",
    "pdata = PipeDataset(input_dir=global_config[\"path_to_test_cifar10\"],\n",
    "    augmentation=dict2transformer(test_augmentation,view=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca362de1-b68b-45c8-94f6-853afff878aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa=eval_linear(pdata, models=collate, device=global_config[\"device\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f9096-89ab-4926-8c60-cca73920c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed89fa6-f9b9-4af6-8531-da9c2729d020",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a19fd-fa88-4c31-a829-e689313f04d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
