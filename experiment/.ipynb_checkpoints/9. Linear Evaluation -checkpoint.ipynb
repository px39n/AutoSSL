{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60f99c9-6b85-40f6-8c0f-a3934044da62",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af985175-ec09-4cf7-a2df-5bededfbb6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset=torchvision.datasets.CocoDetection(root=\"D:/Datasets/CoCo/Data\",annFile=\"D:/Datasets/CoCo/ann\", download = True)\n",
    "#train_dataset=torchvision.datasets.INaturalist(root=\"D:/Datasets/INaturalist\",version=\"2021_valid\", download = True)\n",
    "#train_dataset=torchvision.datasets.INaturalist(root=\"D:/Datasets/INaturalist\",version=\"2021_train\", download = True)\n",
    "#train_dataset=torchvision.datasets.VOCDetection(root=\"D:/Datasets/VOC07\",year=\"2007\", download = True)\n",
    "#train_dataset=torchvision.datasets.VOCDetection(root=\"D:/Datasets/VOC07-12\",year=\"train\", download = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pipe_loadckpt(ckpt):\n",
    "\n",
    "    checkpoint = torch.load(ckpt)\n",
    "    # Extract only backbone state_dict\n",
    "    state_dict_backbone = {k: v for k, v in checkpoint['state_dict'].items() if 'backbone' in k and 'momentum' not in k}\n",
    "    # Remove 'backbone.' prefix in state_dict keys\n",
    "    state_dict_backbone = {k.replace('backbone.', ''): v for k, v in state_dict_backbone.items()}\n",
    "    #state_dict_backbone.keys()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        model_temp=pipe_backbone(\"resnet18_5layer\")[0]\n",
    "        model_temp.load_state_dict(state_dict_backbone)\n",
    "        model=model_temp\n",
    "        print(\"Successfully load resnet18_5layer\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        model_temp=pipe_backbone(\"resnet18_5layer_split8\")[0]\n",
    "        model_temp.load_state_dict(state_dict_backbone)\n",
    "        model=model_temp\n",
    "        print(\"Successfully load resnet18_5layer_split8\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        model_temp=pipe_backbone(\"resnet18\")[0]\n",
    "        model_temp.load_state_dict(state_dict_backbone)\n",
    "        model=model_temp\n",
    "        print(\"Successfully load resnet18\")\n",
    "    except:\n",
    "        #raise ValueError(\"Cannot detect the current ckpt\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return model\n",
    "    except:\n",
    "        raise ValueError(\"Cannot detect the current ckpt\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def pipe_eval_linear(max_epochs,\n",
    "                     accelerator,\n",
    "                     devices,\n",
    "                     log_dir,\n",
    "                     model,\n",
    "                     num_classes,\n",
    "                     feature_dim,\n",
    "                     batch_size,\n",
    "                     check_val_every_n_epoch,\n",
    "                     train_dataloader,\n",
    "                     val_dataloader,\n",
    "                    ):\n",
    "    from pytorch_lightning import LightningModule, Trainer\n",
    "    # Train linear classifier.\n",
    "    metric_callback = MetricCallback()\n",
    "    trainer = Trainer(\n",
    "        max_epochs=15,\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        callbacks=[\n",
    "            LearningRateMonitor(),\n",
    "            DeviceStatsMonitor(),\n",
    "            metric_callback,\n",
    "        ],\n",
    "        logger=TensorBoardLogger(save_dir=str(log_dir), name=\"linear_eval\"),\n",
    "        check_val_every_n_epoch =check_val_every_n_epoch,\n",
    "\n",
    "\n",
    "    )\n",
    "    classifier = LinearClassifier(\n",
    "        model=model,\n",
    "        batch_size_per_device=batch_size,\n",
    "        feature_dim=feature_dim,\n",
    "        num_classes=num_classes,\n",
    "        freeze_model=True,\n",
    "    )\n",
    "    trainer.fit(\n",
    "        model=classifier,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "    for metric in [\"val_top1\", \"val_top5\"]:\n",
    "        print(f\"max linear {metric}: {max(metric_callback.val_metrics[metric])}\")\n",
    "        \n",
    "    return max(metric_callback.val_metrics[\"val_top1\"]),max(metric_callback.val_metrics[\"val_top5\"])\n",
    "\n",
    "\n",
    "def pipe_eval_knn(\n",
    "                     accelerator,\n",
    "                     devices,\n",
    "                     log_dir,\n",
    "                     model,\n",
    "                     num_classes,\n",
    "                     feature_dim,\n",
    "                     batch_size,\n",
    "                     train_dataloader,\n",
    "                     val_dataloader,\n",
    "                    ):\n",
    "    from pytorch_lightning import LightningModule, Trainer\n",
    "    classifier = KNNClassifier(\n",
    "        model=model,\n",
    "        num_classes=num_classes,\n",
    "        feature_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    # Run KNN evaluation.\n",
    "    metric_callback = MetricCallback()\n",
    "    trainer = Trainer(\n",
    "        max_epochs=1,\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        logger=TensorBoardLogger(save_dir=str(log_dir), name=\"knn_eval\"),\n",
    "        callbacks=[\n",
    "            DeviceStatsMonitor(),\n",
    "            metric_callback,\n",
    "        ],\n",
    "    )\n",
    "    trainer.fit(\n",
    "        model=classifier,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "    for metric in [\"val_top1\", \"val_top5\"]:\n",
    "        print(f\"knn {metric}: {max(metric_callback.val_metrics[metric])}\")\n",
    "    return max(metric_callback.val_metrics[\"val_top1\"]),max(metric_callback.val_metrics[\"val_top5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2089115a-30d4-41cc-b63a-8ddb49e832ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load resnet18\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    " \n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import DeviceStatsMonitor, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.transforms.utils import IMAGENET_NORMALIZE\n",
    "from lightly.utils.benchmarking import LinearClassifier, MetricCallback,KNNClassifier\n",
    "import torchvision\n",
    "import sys \n",
    "import torch\n",
    "sys.path.append(\"C:/Users/isxzl/OneDrive/Code/AutoSSL\")\n",
    "from autoSSL.models import pipe_backbone\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "inatur_train_dir= r\"D:\\Datasets\\INaturalist\\2021_valid\\val\" # r\"D:\\Datasets\\VOC2007\\train\" #\"D:/Datasets/TinyImageNet/train/\"\n",
    "inatur_val_dir=  r\"D:\\Datasets\\INaturalist\\2021_valid\\val\"\n",
    "natur=[inatur_train_dir,inatur_val_dir, 10000]\n",
    "cifar_train_dir=r\"D:\\Datasets\\cifar10\\train\"\n",
    "cifar_test_dir=r\"D:\\Datasets\\cifar10\\test\"\n",
    "cifar=[cifar_train_dir,cifar_test_dir,10,32]\n",
    "\n",
    "log_dir=\"Linear_log\"\n",
    "batch_size= 256\n",
    "num_workers=6\n",
    "accelerator=\"cuda\"\n",
    "devices=1\n",
    "feature_dim=512\n",
    "max_epochs=5\n",
    "check_val_every_n_epoch=5\n",
    "# [\"BYOL\",\"BYOL_Mean\",\"SimCLR\",\"SimCLR\",\"SimCLR\",\"SimCLR\",\"SimCLR\",\"SimCLR\"]\n",
    "md_name=\"VICREG\"\n",
    "ckpt_dir=f\"C:/Users/isxzl/OneDrive/Code/AutoSSL/experiment/benchmark_logs/800epoch/{md_name}/checkpoints/epoch=799-step=77600.ckpt\"\n",
    "train_dir,val_dir,num_classes,input_size=cifar\n",
    "\n",
    "model=pipe_loadckpt(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebc81ff3-9a1a-4201-8904-188ab11858c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "# Define transform to convert data from PyTorch tensor to PIL image\n",
    "#transform = transforms.Compose([transforms.Resize((32,32))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"D:\\Datasets/STL10\",Train=True, download=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e1b24d-31b9-4a8a-9330-82fd81c65ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load resnet18_5layer_split8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "checkpoint = torch.load(ckpt_dir)\n",
    "checkpoint['state_dict'].keys()\n",
    "state_dict_backbone = {k: v for k, v in checkpoint['state_dict'].items() if 'backbone' in k and 'momentum' not in k}\n",
    "    # Remove 'backbone.' prefix in state_dict keys\n",
    "state_dict_backbone = {k.replace('backbone.', ''): v for k, v in state_dict_backbone.items()}\n",
    "\n",
    " \n",
    "model=pipe_backbone(\"resnet18_5layer\")[0]\n",
    "#print(checkpoint[\"state_dict\"].keys())\n",
    "len(checkpoint[\"state_dict\"][\"backbone.2.0.bn1.running_mean\"])\n",
    "model=pipe_loadckpt(ckpt_dir)\n",
    "#len(state_dict_backbone[\"2.0.bn1.running_mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f5ada2-05de-4181-9131-e2311a39b2f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0391f783-c325-45ea-9b0c-57060ec3933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def pipe_eval_dataloader(input_size,batch_size,train_dir,val_dir):\n",
    "\n",
    "    train_transform = T.Compose(\n",
    "        [\n",
    "            T.Resize(input_size),\n",
    "            #T.RandomResizedCrop(input_size),\n",
    "            #T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=IMAGENET_NORMALIZE[\"mean\"], std=IMAGENET_NORMALIZE[\"std\"]),\n",
    "        ]\n",
    "    )\n",
    "    train_dataset = LightlyDataset(input_dir=train_dir, transform=train_transform)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    # Setup validation data.\n",
    "    val_transform = T.Compose(\n",
    "        [\n",
    "            T.Resize(input_size), # This forsmall datasets\n",
    "            #T.RandomResizedCrop(input_size),\n",
    "            #T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=IMAGENET_NORMALIZE[\"mean\"], std=IMAGENET_NORMALIZE[\"std\"]),\n",
    "        ]\n",
    "    )\n",
    "    val_dataset = LightlyDataset(input_dir=str(val_dir), transform=val_transform)\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        persistent_workers=True,\n",
    "        shuffle=False, \n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "\n",
    "    return train_dataloader,val_dataloader\n",
    "trainl_loaders,val_loader=pipe_eval_dataloader(input_size,batch_size=256,train_dir=train_dir,val_dir=val_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151a43e2-bea6-468d-af98-f6ed18bd8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pipe_loadckpt(ckpt_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c3fb1-a9da-4423-a7a9-a602fa8abe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | model               | Sequential       | 11.2 M\n",
      "1 | classification_head | Linear           | 5.1 K \n",
      "2 | criterion           | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|██████████████████████████████████████▊    | 177/196 [00:06<00:00, 29.39it/s, v_num=14, train_loss=2.200]"
     ]
    }
   ],
   "source": [
    "result=pipe_eval_linear(max_epochs=max_epochs,\n",
    "                     accelerator=accelerator, \n",
    "                     devices=devices, \n",
    "                     log_dir=log_dir,\n",
    "                     model=model,\n",
    "                     num_classes=num_classes,\n",
    "                     feature_dim=feature_dim ,\n",
    "                     batch_size=batch_size,\n",
    "                     check_val_every_n_epoch=check_val_every_n_epoch,\n",
    "                     train_dataloader=trainl_loaders,\n",
    "                     val_dataloader=val_loader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebec5a4-97ec-4bb2-b211-5049ac0cecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pipe_eval_knn(\n",
    "                     accelerator=accelerator, \n",
    "                     devices=devices, \n",
    "                     log_dir=log_dir,\n",
    "                     model=model,\n",
    "                     num_classes=num_classes,\n",
    "                     feature_dim=feature_dim ,\n",
    "                     batch_size=batch_size,\n",
    "                     train_dataloader=trainl_loaders,\n",
    "                     val_dataloader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be53f3e-3f87-4bd9-8b17-89597b00d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pipe_eval_knn(\n",
    "                     accelerator=accelerator, \n",
    "                     devices=devices, \n",
    "                     log_dir=log_dir,\n",
    "                     model=model,\n",
    "                     num_classes=num_classes,\n",
    "                     feature_dim=feature_dim ,\n",
    "                     batch_size=batch_size,\n",
    "                     train_dataloader=trainl_loaders,\n",
    "                     val_dataloader=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e410670-4581-480a-a7ff-89a1570a50ac",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff4d47-e560-490f-8621-4d4a9d08795b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddc38413-ab89-4be3-b819-19cf46d2b0d8",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87129ce0-6f50-4d6d-8577-6069f6917418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import DeviceStatsMonitor, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.transforms.utils import IMAGENET_NORMALIZE\n",
    "from lightly.utils.benchmarking import LinearClassifier, MetricCallback\n",
    "from lightly.utils.scheduler import CosineWarmupScheduler\n",
    "\n",
    "\n",
    "class FinetuneLinearClassifier(LinearClassifier):\n",
    "    def configure_optimizers(self):\n",
    "        parameters = list(self.classification_head.parameters())\n",
    "        parameters += self.model.parameters()\n",
    "        optimizer = SGD(\n",
    "            parameters,\n",
    "            lr=0.05 * self.batch_size_per_device * self.trainer.world_size / 256,\n",
    "            momentum=0.9,\n",
    "            weight_decay=0.0,\n",
    "        )\n",
    "        scheduler = {\n",
    "            \"scheduler\": CosineWarmupScheduler(\n",
    "                optimizer=optimizer,\n",
    "                warmup_epochs=0,\n",
    "                max_epochs=self.trainer.estimated_stepping_batches,\n",
    "            ),\n",
    "            \"interval\": \"step\",\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    " \n",
    "print(\"Running fine-tune evaluation...\")\n",
    "\n",
    "# Setup training data.\n",
    "train_transform = T.Compose(\n",
    "    [\n",
    "        T.RandomResizedCrop(input_size),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=IMAGENET_NORMALIZE[\"mean\"], std=IMAGENET_NORMALIZE[\"std\"]),\n",
    "    ]\n",
    ")\n",
    "train_dataset = LightlyDataset(input_dir=str(train_dir), transform=train_transform)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size_per_device,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "# Setup validation data.\n",
    "val_transform = T.Compose(\n",
    "    [\n",
    "        T.Resize(input_size),\n",
    "        #T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=IMAGENET_NORMALIZE[\"mean\"], std=IMAGENET_NORMALIZE[\"std\"]),\n",
    "    ]\n",
    ")\n",
    "val_dataset = LightlyDataset(input_dir=str(val_dir), transform=val_transform)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size_per_device,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "# Train linear classifier.\n",
    "metric_callback = MetricCallback()\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    callbacks=[\n",
    "        LearningRateMonitor(),\n",
    "        DeviceStatsMonitor(),\n",
    "        metric_callback,\n",
    "    ],\n",
    "    logger=TensorBoardLogger(save_dir=str(log_dir), name=\"finetune_eval\"),\n",
    "    check_val_every_n_epoch =5,\n",
    "\n",
    ")\n",
    "classifier = FinetuneLinearClassifier(\n",
    "    model=model,\n",
    "    batch_size_per_device=batch_size_per_device,\n",
    "    feature_dim=feature_dim,\n",
    "    num_classes=num_classes,\n",
    "    freeze_model=False,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=classifier,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "for metric in [\"val_top1\", \"val_top5\"]:\n",
    "    print(f\"max finetune {metric}: {max(metric_callback.val_metrics[metric])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02530b06-7a77-419f-b543-a385584e4b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
