{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4533ee81-d579-4867-b15b-aa7f3f8f385f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment Introduction\n",
    "\n",
    "Background, \n",
    "In order to do ablation experiment, we have diffculty like\n",
    "1. most of them are same, we have to repeat many times.\n",
    "2. too many model, config, code hard to manage and save. too messy\n",
    "\n",
    "\n",
    "For all kind of SSL training workflow, we have to define the hyperparameters includes 4 aspect,\n",
    "Dataset\n",
    "Model\n",
    "Training\n",
    "Saving COnfig\n",
    "\n",
    "\n",
    "\n",
    "How to Use this Experiment?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5e60f-6c7d-47b6-8b30-5ad2e6c94b09",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71222088-d62f-40fc-b935-f9c8ee99a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import config\n",
    "import sys \n",
    "sys.path.append(\"C:/Users/isxzl/OneDrive/Code/AutoSSL\")\n",
    "import torch\n",
    "import yaml\n",
    "from torchvision.transforms import RandomRotation,GaussianBlur,ColorJitter\n",
    "from autoSSL.evaluate import eval_KNN,eval_linear,eval_KNNplot,pipe_collate\n",
    "from autoSSL.models import BarlowTwins, BYOL, MoCo, SimCLR, SimSiam, VICReg ,pipe_model \n",
    "from autoSSL.utils import embedding_feature,ck_callback,dict2transformer,join_dir,ContinuousCSVLogger  \n",
    "from autoSSL.data import PipeDataset\n",
    "from autoSSL.train import Trainer\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eba85e-c2d4-4ed3-a276-2b03ff82f764",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Global Baseline Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb0e5479-43a3-4b63-b9e2-b8ce70103290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML file\n",
    "with open('global.yaml', 'r') as file:\n",
    "    global_config = yaml.safe_load(file)\n",
    "\n",
    "# Write your experiment notebook name here\n",
    "global_config[\"experiment\"]=\"backbone VS model\"     \n",
    "    \n",
    "# Define global view function\n",
    "global_SSL_augmentation = {\n",
    "    'RandomResizedCrop': {'size': (global_config[\"input_size\"], global_config[\"input_size\"])},\n",
    "    'RandomApply':{'transforms':[RandomRotation(degrees=90)], 'p':0.8},\n",
    "    'RandomHorizontalFlip': {'p': 0.5},\n",
    "    'RandomVerticalFlip':  {'p':0.5},\n",
    "    'RandomApply':{'transforms': [ColorJitter(brightness=0.04,contrast=0.04,saturation=0.02,hue=0.01)], 'p':0.8},\n",
    "    'RandomGrayscale' :{'p':0.2},\n",
    "    'RandomSolarize':{'threshold':128, 'p':0.1},\n",
    "    'RandomApply':{'transforms':[GaussianBlur(kernel_size=3,sigma=(0.2, 2))],'p':0.8},\n",
    "    'ToTensor': {},\n",
    "    'Normalize': {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f84c3-1365-48e8-8ac9-6fdeb5c7a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a869f3e-3e94-4d05-bec5-6fdd31695b58",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e6970-4604-485e-bd37-60383de96b81",
   "metadata": {
    "tags": []
   },
   "source": [
    "## vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51c7c16f-0305-4293-a8e6-2920c08a6954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU RAM Free: 16399MB | Used: 7756MB | Util  32% | Total 24564MB\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUs = GPUtil.getGPUs()\n",
    "gpu = GPUs[0]\n",
    "import torch\n",
    "print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793fbb9-671d-4286-a3bc-9fcf592bd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1352c0-9e27-470a-919d-af85ba9365b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"resnet18\", \"resnet18_pretrained\", \"resnet50\", \"resnet50_pretrained\", \"vit_64\",\"mobilenet_v3\", \"mobilenet_v3_pretrained\", \"resnet50\",\n",
    "for backbone_name in[\"efficientnet_b5\", \"efficientnet_b5_pretrained\"]:\n",
    "\n",
    "    # MAKE YOUR OWN CONFIG\n",
    "    config=global_config.copy()\n",
    "    # Fill the config\n",
    "    SSL_augmentation=global_SSL_augmentation.copy()\n",
    "    config[\"name\"]=f\"VICReg_backbone_{backbone_name}\"\n",
    "    config[\"backbone\"]=backbone_name\n",
    "    config[\"model\"]=\"VICReg\"\n",
    "    config[\"batch\"]=512\n",
    "    config[\"prjhead_dim\"]=2048\n",
    "    # THIS IS THE CODE TO LOAD DATASET\n",
    "    pdata= PipeDataset(config=config,augmentation=dict2transformer(SSL_augmentation,view=config[\"view\"]))\n",
    "    # THIS IS THE CODE TO LOAD MODEL\n",
    "    pmodel=pipe_model(config=config)\n",
    "\n",
    "    # Use this if you want to START a train\n",
    "    trainer=Trainer(config, model_mode=\"start\",precision='16-mixed')\n",
    "    trainer.fit(pmodel, pdata.dataloader)  \n",
    "\n",
    "    del pdata\n",
    "    del pmodel\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    # Use this if you want to CONTINUE to train\n",
    "    #trainer1=Trainer(config, model_mode=\"continue\", extra_epoch=0)\n",
    "    #trainer1.fit(pmodel, pdata.dataloader,ckpt_path=\"latest\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a70d5bb-279d-47b1-8850-dd2288e5e568",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb66c1a-89fa-4ce2-9f35-92ba04726170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5d877c7-b5f9-4dd9-ae01-04f29327fe52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67682be1-2079-464a-97e5-26c474f5bdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50686839-6777-4c26-b7f6-02b871ac184a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5cdb99-4cac-4e1d-8b01-eb338e9fcb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def embed(x, embedding_model, device):\n",
    "    embedding_model.eval()\n",
    "    embedding_model.to(device)\n",
    "    x = x.float().to(device)   # remove the unsqueeze operation\n",
    "    return embedding_model(x).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def eval_linear(pipe_data, models, device='cuda', split=None, test=None):\n",
    "    '''\n",
    "    Parameters:\n",
    "    pipe_data (PipeDataset): The whole data as a PipeDataset object\n",
    "    models (dict/torch.nn.Module): Model dict returned by `pipe_collate` or a single model to create embeddings\n",
    "    device (str): Device to perform computations on. Default is 'cuda' if available.\n",
    "    split (float, optional): The ratio of samples to include in the train split.\n",
    "    test (PipeDataset, optional): The test data as a PipeDataset object\n",
    "    '''\n",
    "\n",
    "    # Use split parameter to divide data into train and test if test is not provided\n",
    "    if split is not None and test is None:\n",
    "        train_data, test_data = pipe_data.split(split)\n",
    "    else:\n",
    "        train_data = pipe_data\n",
    "        test_data = test\n",
    "\n",
    "    # Extract features and labels from train and test data\n",
    "    print(\"Load the training and testing dataset\")\n",
    "    X_train, y_train = train_data.array[0], train_data.array[1]\n",
    "    X_test, y_test = test_data.array[0], test_data.array[1]\n",
    "\n",
    "    if isinstance(models, torch.nn.Module):\n",
    "       models = {'name': ['model_0'], 'model': [models], 'address': None} \n",
    "    if isinstance(models, list):\n",
    "        models = {'name': ['model_'+str(i) for i in range(0,len(models))], 'model': models, 'address': None}\n",
    "   \n",
    "    # Initialize the results list\n",
    "    results = []\n",
    "\n",
    "    # Iterate over models and calculate accuracy\n",
    "    for i, embedding_model in enumerate(tqdm(models['model'])):\n",
    "        # Get the embeddings for train and test data\n",
    "        X_train_embedding = [embed(x, embedding_model, device) for x in DataLoader(X_train, batch_size=128)]\n",
    "        X_train_embedding = np.concatenate(X_train_embedding)\n",
    "\n",
    "        X_test_embedding = [embed(x, embedding_model, device) for x in DataLoader(X_test, batch_size=128)]\n",
    "        X_test_embedding = np.concatenate(X_test_embedding)\n",
    "\n",
    "        if X_test_embedding is None or np.any(np.isnan(X_train_embedding)):\n",
    "            accuracy = 'model_collapse'\n",
    "        else:\n",
    "            # Initialize the SGDClassifier and train it\n",
    "            clf = SGDClassifier()\n",
    "            clf.fit(X_train_embedding, y_train)\n",
    "\n",
    "            # Predict labels for the test data and calculate accuracy\n",
    "            X_test_predicted = clf.predict(X_test_embedding)\n",
    "            accuracy = accuracy_score(y_test, X_test_predicted)\n",
    "\n",
    "        namee=models[\"name\"][i]\n",
    "        # Append the accuracy to the results\n",
    "        results.append((namee, accuracy))\n",
    "        \n",
    "    if models['address'] is not None:\n",
    "        df = pd.read_csv(models['address'])\n",
    "        df['linear_accuracy'] = [result[1] for result in results]\n",
    "        df.to_csv(models['address'], index=False)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ad6455-b8c3-4d5d-b6eb-5627bd52fbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collating the models' (evaluating) information to experiment_checkpoints/backbone VS model/^VICReg_backbone_._$.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_augmentation = {\n",
    "    'RandomResizedCrop': {'size': (global_config[\"input_size\"], global_config[\"input_size\"])},\n",
    "    'ToTensor': {},\n",
    "    'Normalize': {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "}\n",
    "collate =pipe_collate(address=\"experiment_checkpoints/backbone VS model/\", reg=\"^VICReg_backbone_.*$\")\n",
    "\n",
    "pdata = PipeDataset(input_dir=global_config[\"path_to_test_cifar10\"],\n",
    "    augmentation=dict2transformer(test_augmentation,view=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca362de1-b68b-45c8-94f6-853afff878aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the training and testing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:04<00:00, 1884.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:04<00:00, 1917.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2001/2001 [00:01<00:00, 1503.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2001/2001 [00:01<00:00, 1804.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:54<00:00,  6.02s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aaa=eval_linear(pdata, models=collate, device=global_config[\"device\"], split=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f9096-89ab-4926-8c60-cca73920c337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VICReg_backbone_efficientnet_b5', 'model_collapse'),\n",
       " ('VICReg_backbone_efficientnet_b5_pretrained', 0.30684657671164417),\n",
       " ('VICReg_backbone_mobilenet_v3', 'model_collapse'),\n",
       " ('VICReg_backbone_mobilenet_v3_pretrained', 0.43228385807096453),\n",
       " ('VICReg_backbone_resnet18', 0.22938530734632684),\n",
       " ('VICReg_backbone_resnet18_pretrained', 0.32233883058470764),\n",
       " ('VICReg_backbone_resnet50', 'model_collapse'),\n",
       " ('VICReg_backbone_resnet50_pretrained', 0.3363318340829585),\n",
       " ('VICReg_backbone_vit_64', 0.1054472763618191)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " aaa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
